{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 437 - Deep Learning - Assignment 4\n",
    "\n",
    "*__Submission Instructions:__*\n",
    "- Rename this notebook to `hw4_rollnumber.ipynb` before submission on LMS.\n",
    "- Code for all the tasks must be written in this notebook (you do not need to submit any other files).\n",
    "- The output of all cells must be present in the version of the notebook you submit.\n",
    "- The university honor code should be maintained. Any violation, if found, will result in disciplinary action. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn')\n",
    "import seaborn as sns\n",
    "\n",
    "from keras.models import load_model\n",
    "from keras.applications import vgg16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## Overview\n",
    "\n",
    "In this assignment you will be exploring a few important concepts used in the deep learning projects:\n",
    "- Working with satellite imagery data\n",
    "- Dataset annotation\n",
    "- Fine-tuning / Transfer Learning\n",
    "- Unsupervised feature representation with Autoencoder\n",
    "- Comparison of end-to-end trained model with finetuned model\n",
    "\n",
    "We will be using two datasets, the links are provided to you. You will also be working with three pretrained models, which have been provided to you. You are **highly** encouraged to explore the datasets and model architectures in order to get the most out of this assignment. \n",
    "\n",
    "**_Datasets:_**\n",
    "- Brick Kiln (Nepal) - available [here]()\n",
    "- UC Merced Land Use - available [here](http://weegee.vision.ucmerced.edu/datasets/landuse.html)\n",
    "\n",
    "**_Pretrained Models:_**\n",
    "- ResNet18 pretrained on Brick Kiln (Lahore) - available [here]()\n",
    "- Autoencoder pretrained on GT Cross View and fine tuned on UC Merced - available [here]()\n",
    "- VGG16 pretrained on ImageNet - available in `keras.applications` (consult relevant documentation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "\n",
    "Let's start with a binary classification problem. \n",
    "\n",
    "The Brick Kiln (Nepal) dataset you have been given consists of 100 tiles at zoom level 17. A script to break up these tiles into 64 sub-tiles of zoom 20 has also been given to you. Your job is to:\n",
    "- Split 100 images into 6400 images using the script\n",
    "- Manually annotate the dataset by moving the kiln pictures into one folder and non-kiln picutures into other folder.\n",
    "- Code up a generator to properly load the images and corresponding binary labels into a model. You have to resize images into 224X224X3\n",
    "\n",
    "*Scale images between 0 and 1 and apply mean subtraction in the generator*\n",
    "\n",
    "*Each of you has been given unique 100 tiles, so for the love of God do not get annotated data from someone else.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def brick_kiln_generator(...):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "\n",
    "Now you will evaluate performance of a pretrained (on Brick Kiln Lahore dataset) ResNet18 model using the generator made in Task1. You will:\n",
    "- Obtain predictions for the entire dataset\n",
    "- Construct a binary confusion matrix and visualize it as a heatmap\n",
    "\n",
    "*You can use scikit-learn's `metrics.confusion_matrix` function. Consult the relevant documentation.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3\n",
    "\n",
    "Next you will employ Transfer Learning and finetune the pretrained ResNet18 model you used in Task2 to better fit the Brick Kiln (Nepal) dataset. You will:\n",
    "- Freeze everything except the FC layers and train it using the generator from Task1 (using appropriate hyperparameters)\n",
    "- Construct a binary confusion matrix and visualize it as a heatmap\n",
    "- Compare this confusion matrix with the one made in Task2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet18_pretrained = load_model(...)\n",
    "resnet18_pretrained.summary()\n",
    "resnet18_pretrained.compile(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4\n",
    "\n",
    "Now we will look at a multiclass classification problem.\n",
    "\n",
    "The UC Merced Land Use dataset consists of 21 classes, ranging from airplanes to forests to tennis courts. Let's add kilns to it since you worked so hard to annotate the dataset in Task1. You will:\n",
    "- Download the dataset and add a new folder (following the already existing folder structure) corresponding to brick kilns\n",
    "- Code up a generator to properly load the images and corresponding 22-class labels into a model. You have to resize images into 224X224X3 for VGG16\n",
    "\n",
    "*Scale images between 0 and 1 and apply mean subtraction in the generator*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def land_use_generator(...):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5\n",
    "\n",
    "Next you will again employ Transfer Learning and finetune the pretrained (on ImageNet) VGG16 to better fit the modified Land Use dataset. You will:\n",
    "- Change the number of nodes in the last FC layer according to the number of classes i.e. 22 \n",
    "- Freeze everything except the FC layers and train it using the generator from Task4 (using appropriate hyperparameters)\n",
    "- Construct a multi-class confusion matrix and visualize it as a heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 619s 11us/step\n"
     ]
    }
   ],
   "source": [
    "vgg_imagenet = vgg16.VGG16(include_top=False, weights='imagenet')\n",
    "for l in vgg_imagenet.layers:\n",
    "    l.freeze = True\n",
    "\n",
    "# add new FC layers here\n",
    "\n",
    "# print summary and compile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6\n",
    "\n",
    "Now you will make use of Unsupervised Representation Learning as studied in class. You have been provided with a pretrained autoencoder (just the encoder part) and you will use it to obtain deep features for the modified UC Merced Land Use dataset. You will have to:\n",
    "- Obtain predictions for the entire dataset\n",
    "- Save then in an appropriate fashion\n",
    "\n",
    "*Keep in mind that this model takes input of shape 256X256X3 so you need to resize the images before feeding them into this model*\n",
    "\n",
    "*Try to think about how you could use the generator from Task4 to create another generator which would yield encoded features along with labels instead of raw images*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 7\n",
    "\n",
    "Now you will train a classifier from scratch to discriminate the 22 classes based on the deep features you extracted in Task6. You will:\n",
    "- Train a classifier with the following architecture\n",
    "> 1D conv 3x1 -> 1D conv 3x1 -> FC 256 -> FC 22\n",
    "- Construct a multiclass confusion matrix and visualize it as a heatmap\n",
    "- Compare this confusion matrix with the one made in Task5\n",
    "\n",
    "*The input to this model will be the deep feature tensor obtained in Task6, so use appropriate input shape*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 8\n",
    "\n",
    "Now you will explore another use of the deep features extracted in Task6. Content Based Image Retrieval (CBIR) is the task of searching for visually similar images from a dataset. *Think Google image search.* This concept can obviously be applied on other forms of data like text, audio or video as well. In this task you will:\n",
    "- Implement a function which will take three inputs and returns a list of visually similar images. The inputs would be\n",
    "> An image from the dataset `im` <br />\n",
    "The number of search results to return `n` <br />\n",
    "A string representing the distance metric used for comparisons `dist`\n",
    "- Use some images to compare the effects of these distance metrics on the output\n",
    "> Euclidean <br />\n",
    "Cosine <br />\n",
    "Mahalanobis\n",
    "\n",
    "*Look up the documentation for Scipy's `spatial.distance` module. It is your best friend in this task.*\n",
    "\n",
    "*If you made a generator in Task6, you can very easily use it in this task as well*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cbir(im, n, dist):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
